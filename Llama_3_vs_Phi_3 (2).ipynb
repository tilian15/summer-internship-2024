{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d36f594c833c4f5b9c86587651510d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45bb4774097f446884943521ce1de88e",
              "IPY_MODEL_b13cdf8601bf4e8dab93f0b293291b0a",
              "IPY_MODEL_c1fb9c39116246ff866a417a95929094"
            ],
            "layout": "IPY_MODEL_5875b6c41e4147ada22d505d37c3f54d"
          }
        },
        "45bb4774097f446884943521ce1de88e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b62cb68e064425197b25e7aa75aaa86",
            "placeholder": "​",
            "style": "IPY_MODEL_6ceb1d05f8c5410daf0e573b639f04da",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b13cdf8601bf4e8dab93f0b293291b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f548c5b9e55a41d4bf0fdc4b5db2b9cf",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95640dfbb5a94389b1ed0d16b9eb15ec",
            "value": 4
          }
        },
        "c1fb9c39116246ff866a417a95929094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c2f28cb5eef4b33bbe891375409ca0a",
            "placeholder": "​",
            "style": "IPY_MODEL_375af7a1a6cc4ec494f53596224936f6",
            "value": " 4/4 [00:14&lt;00:00,  3.27s/it]"
          }
        },
        "5875b6c41e4147ada22d505d37c3f54d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b62cb68e064425197b25e7aa75aaa86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ceb1d05f8c5410daf0e573b639f04da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f548c5b9e55a41d4bf0fdc4b5db2b9cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95640dfbb5a94389b1ed0d16b9eb15ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c2f28cb5eef4b33bbe891375409ca0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "375af7a1a6cc4ec494f53596224936f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DAodxYxo1Wm"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"The Importance of Staying Active During the Pandemic The COVID-19 pandemic has forced people worldwide to stay indoors, leading to a significant decrease in physical activity levels. With lockdowns, social distancing, and remote work, people are spending more time sitting in front of screens, leading to an increase in sedentary behaviour. However, staying active during the pandemic is crucial, not just for physical health but also for mental well-being. Physical activity is known to have numerous health benefits, including improved cardiovascular health, weight management, and a reduced risk of chronic diseases such as diabetes and certain types of cancer. Exercise also releases endorphins, which help alleviate stress and anxiety, both of which have become increasingly prevalent due to the pandemic. While staying active during the pandemic may be challenging, there are several ways to do so. One option is to take up home workouts that require little to no equipment. With numerous workout videos available online, people can find routines that suit their fitness levels and preferences. Another option is to engage in outdoor activities such as cycling, running, or hiking, provided that social distancing guidelines are followed. Besides physical health, staying active during the pandemic can also boost mental well-being. Exercise can help improve mood and cognitive function, leading to increased productivity and a positive outlook on life. With the pandemic causing stress and uncertainty, engaging in physical activity can help individuals cope and improve their mental health. Furthermore, staying active during the pandemic can help maintain a sense of routine and structure, which is essential for mental well-being. With remote work and social distancing disrupting daily routines, physical activity can provide a sense of normalcy and stability, leading to increased feelings of control and self-efficacy. In conclusion, staying active during the pandemic is vital for both physical and mental well-being. With numerous options available, individuals can find ways to engage in physical activity that suits their preferences and fitness levels. Exercise not only provides numerous health benefits but also helps alleviate stress and anxiety during these challenging times. So, get up, get moving, and stay active - your body and mind will thank you for it.\n",
        "\n",
        "\n",
        "\n",
        "The Benefits of Mindfulness Meditation for Mental Health\n",
        "\n",
        "Mental health issues affect millions of people worldwide, with conditions such as anxiety, depression, and stress becoming increasingly prevalent. While traditional treatments such as therapy and medication can be effective, many people are turning to mindfulness meditation as a complementary therapy to improve their mental health. Mindfulness meditation is a technique that involves paying attention to the present moment while remaining non-judgmental and accepting of one's thoughts and feelings. This article explores the benefits of mindfulness meditation for mental health and how to incorporate it into your daily routine.\n",
        "\n",
        "Reduced Symptoms of Anxiety and Depression\n",
        "\n",
        "Studies have shown that mindfulness meditation can be effective in reducing symptoms of anxiety and depression. One study found that an eight-week mindfulness-based stress reduction program led to significant reductions in symptoms of anxiety and depression in participants. Another study found that mindfulness-based cognitive therapy was as effective as medication in preventing relapse in patients with depression. Mindfulness meditation helps people become more aware of their thoughts and feelings, allowing them to observe and accept them rather than becoming overwhelmed by them. This increased awareness and acceptance can lead to a reduction in symptoms of anxiety and depression.\n",
        "\n",
        "Lower levels of stress\n",
        "\n",
        "Stress is a common problem for many people, and it can have a negative impact on mental health. Mindfulness meditation has been shown to lower levels of stress in individuals. One study found that a mindfulness-based stress reduction program led to a reduction in cortisol, the stress hormone, in participants. Another study found that mindfulness meditation improved mood and reduced stress in healthcare professionals.\n",
        "\n",
        "Improved Emotional Regulation\n",
        "\n",
        "Mindfulness meditation can help improve emotional regulation, allowing people to respond to situations in a more positive and productive way. Research has shown that mindfulness meditation can improve emotional regulation in individuals with anxiety, depression, and borderline personality disorder. By practicing mindfulness meditation, people can become more aware of their emotions and learn to accept them without judgment, leading to improved emotional regulation.\n",
        "\n",
        "Increased Self-Awareness and Self-Acceptance\n",
        "\n",
        "Paneer kadhai is the dish of the day.\n",
        "\n",
        "Mindfulness meditation can help people become more self-aware and accepting of themselves. By becoming more aware of their thoughts and feelings, individuals can learn to accept themselves without judgment. This increased self-awareness and self-acceptance can lead to improved self-esteem and self-confidence.\n",
        "\n",
        "Improved Cognitive Function\n",
        "\n",
        "Research has shown that mindfulness meditation can improve cognitive function in individuals of all ages. One study found that mindfulness meditation improved working memory capacity in young adults. Another study found that mindfulness meditation improved attention and cognitive control in individuals with ADHD. By practicing mindfulness meditation, people can improve their cognitive function, leading to increased productivity and better decision-making.\n",
        "\n",
        "How to Incorporate Mindfulness Meditation into Your Daily Routine\n",
        "\n",
        "Incorporating mindfulness meditation into your daily routine can be easy and beneficial for your mental health. Here are some tips for incorporating mindfulness meditation into your daily routine:\n",
        "\n",
        "Start with a few minutes a day\n",
        "\n",
        "Begin by practicing mindfulness meditation for just a few minutes a day. Set aside a specific time each day, such as first thing in the morning or before bed, to practice mindfulness meditation.\n",
        "\n",
        "Focus on your breath\n",
        "\n",
        "Focus on your breath during mindfulness meditation. Pay attention to the sensation of your breath as it enters and leaves your body. If your mind wanders, gently bring your focus back to your breath.\n",
        "\n",
        "Be non-judgmental\n",
        "\n",
        "During mindfulness meditation, be non-judgmental of your thoughts and feelings. Observe them without judgment and accept them as they are.\n",
        "\n",
        "Practice in a quiet space\n",
        "\n",
        "Find a quiet space to practice mindfulness meditation. This could be a room in your home or a quiet outdoor space. Minimize distractions and noise to help you focus.\n",
        "\n",
        "Use guided meditations\n",
        "\n",
        "There are many guided meditations available online and in apps that can help you practice mindfulness meditation. These guided meditations can be helpful for beginners and those who find it difficult to focus on their own.\n",
        "\n",
        "Conclusion\n",
        "\n",
        "Mindfulness meditation is a beneficial practice for mental health, with studies showing improvements in symptoms of anxiety, depression, and stress. By incorporating mindfulness meditation into your daily routine, you can improve emotional regulation, self-awareness, and cognitive function. Start with just a few minutes a day, focus on your breath, and practice in a quiet space. By practicing mindfulness meditation, you can improve your mental health and overall well-being.\n",
        "\n",
        "We introduce phi-3-mini, a 3.8 billion parameter language model trained on 3.3 trillion tokens, whose overall performance, as measured by both academic benchmarks and internal testing, rivals that of models such as Mixtral 8x7B and GPT-3.5 (e.g., phi-3-mini achieves 69% on MMLU and 8.38 on MT-bench), despite being small enough to be deployed on a phone. The innovation lies entirely in our dataset for training, a scaled-up version of the one used for phi-2, composed of heavily filtered web data and synthetic data. The model is also further aligned for robustness, safety, and chat format. We also provide some initial parameter-scaling results with a 7B and 14B models trained for 4.8T tokens, called phi-3-small and phi-3-medium, both significantly more capable than phi-3-mini (e.g., respectively 75% and 78% on MMLU, and 8.7 and 8.9 on MT-bench).\n",
        "\n",
        "In terms of LLM capabilities, while phi-3-mini model achieves similar level of language understanding\n",
        "and reasoning ability as much larger models, it is still fundamentally limited by its size for certain tasks.\n",
        "The model simply does not have the capacity to store too much “factual knowledge”, which can be seen\n",
        "for example with low performance on TriviaQA. However, we believe such weakness can be resolved by\n",
        "augmentation with a search engine. We show an example using the HuggingFace default Chat-UI with\n",
        "phi-3-mini in Figure 4. Another weakness related to model’s capacity is that we mostly restricted the\n",
        "language to English. Exploring multilingual capabilities for Small Language Models is an important\n",
        "next step, with some initial promising results on phi-3-small by including more multilingual data.\n",
        "Despite our diligent RAI efforts, as with most LLMs, there remains challenges around factual inaccuracies (or hallucinations), reproduction or amplification of biases, inappropriate content generation, and\n",
        "safety issues. The use of carefully curated training data, and targeted post-training, and improvements\n",
        "from red-teaming insights significantly mitigates these issues across all dimensions. However, there is\n",
        "significant work ahead to fully address these challenges.\n",
        "7\n",
        "References\n",
        "[AI23] Meta AI. Introducing meta llama 3: The most capable openly available llm to date, 2023.\n",
        "[AON+\n",
        "21] Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David\n",
        "Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, and Charles Sutton. Program\n",
        "synthesis with large language models. arXiv preprint arXiv:2108.07732, 2021.\n",
        "[BJN+\n",
        "22] Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma,\n",
        "Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Kadavath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nelson Elhage, Zac Hatfield-Dodds,\n",
        "Danny Hernandez, Tristan Hume, Scott Johnston, Shauna Kravec, Liane Lovitt, Neel Nanda,\n",
        "Catherine Olsson, Dario Amodei, Tom Brown, Jack Clark, Sam McCandlish, Chris Olah,\n",
        "Ben Mann, and Jared Kaplan. Training a helpful and harmless assistant with reinforcement\n",
        "learning from human feedback, 2022.\n",
        "[BSA+\n",
        "24] Federico Bianchi, Mirac Suzgun, Giuseppe Attanasio, Paul R¨ottger, Dan Jurafsky, Tatsunori\n",
        "Hashimoto, and James Zou. Safety-tuned llamas: Lessons from improving the safety of large\n",
        "language models that follow instructions, 2024.\n",
        "[BZGC19] Yonatan Bisk, Rowan Zellers, Jianfeng Gao, and Yejin Choi. Piqa: Reasoning about physical\n",
        "commonsense in natural language. arXiv preprint arXiv:1911.11641, 2019.\n",
        "[CCE+\n",
        "18] Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick,\n",
        "and Oyvind Tafjord. Think you have solved question answering? try arc, the ai2 reasoning\n",
        "challenge, 2018.\n",
        "[CKB+\n",
        "21] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz\n",
        "Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher\n",
        "Hesse, and John Schulman. Training verifiers to solve math word problems. arXiv preprint\n",
        "arXiv:2110.14168, 2021.\n",
        "[CLC+\n",
        "19] Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and\n",
        "Kristina Toutanova. Boolq: Exploring the surprising difficulty of natural yes/no questions.\n",
        "In Proceedings of the 2019 Conference of the North American Chapter of the Association\n",
        "for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short\n",
        "Papers), pages 2924–2936, 2019.\n",
        "[CTJ+\n",
        "21] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto,\n",
        "Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray,\n",
        "Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin,\n",
        "Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings,\n",
        "Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen\n",
        "Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji,\n",
        "Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh\n",
        "Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage,\n",
        "Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish,\n",
        "Ilya Sutskever, and Wojciech Zaremba. Evaluating large language models trained on code,\n",
        "2021.\n",
        "8\n",
        "[DZZ+\n",
        "24] Yiran Ding, Li Lyna Zhang, Chengruidong Zhang, Yuanyuan Xu, Ning Shang, Jiahang Xu,\n",
        "Fan Yang, and Mao Yang. Longrope: Extending llm context window beyond 2 million tokens,\n",
        "2024.\n",
        "[GZA+\n",
        "23] Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio C´esar Teodoro Mendes, Allie Del Giorno,\n",
        "Sivakanth Gopi, Mojan Javaheripi, Gustavo de Rosa Piero Kauffmann, Olli Saarikivia,\n",
        "Adil Salim, Shital Shah, Harkirat Singh Behl, Xin Wang, S´ebastien Bubeck, Ronen Eldan, Adam Tauman Kalai, Yin Tat Lee, and Yuanzhi Li. Textbooks are all you need. arXiv\n",
        "preprint arXiv:2306.11644, 2023.\n",
        "Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang,\n",
        "Dawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the MATH\n",
        "dataset, 2021.\n",
        "[HBM+\n",
        "22] Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Eliza Rutherford Trevor Cai, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark,\n",
        "Tom Hennigan, Eric Noland, Katie Millican, George van den Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich Elsen, Jack W. Rae, Oriol Vinyals,\n",
        "and Laurent Sifre. Training compute-optimal large language models. arXiv preprint\n",
        "arXiv:2203.15556, 2022.\n",
        "[JBA+\n",
        "23] Mojan Javaheripi, S´ebastien Bubeck, Marah Abdin, Jyoti Aneja, Caio C´esar\n",
        "Teodoro Mendes, Weizhu Chen, Allie Del Giorno, Ronen Eldan, Sivakanth Gopi, Suriya\n",
        "Gunasekar, Piero Kauffmann, Yin Tat Lee, Yuanzhi Li, Anh Nguyen, Gustavo de Rosa, Olli\n",
        "Saarikivi, Adil Salim, Shital Shah, Michael Santacroce, Harkirat Singh Behl, Adam Taumann Kalai, Xin Wang, Rachel Ward, Philipp Witte, Cyril Zhang, and Yi Zhang. Phi-2:\n",
        "The surprising power of small language models. Microsoft Research Blog, 2023.\n",
        "[JCWZ17] Mandar Joshi, Eunsol Choi, Daniel S. Weld, and Luke Zettlemoyer. Triviaqa: A large scale.\n",
        "What is the dish of the day ? Be very precise in your response.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "El0KbZpjpHD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(prompt.split(\" \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZbMtshCpw1f",
        "outputId": "dc863918-1d85-493e-ccfe-0af269fedf83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2013"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import huggingface_hub\n",
        "from google.colab import userdata\n",
        "huggingface_hub.login(token='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', add_to_git_credential=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFXxcIdhuF0n",
        "outputId": "0ecf80a2-8ba0-45a8-daf4-d0a439f84a2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pattern_question = \"Fill in the blank letter '_' in  the pattern 1,8,9,64,25,216,_. Only return the answer\" # Answer is 49"
      ],
      "metadata": {
        "id": "uhnzc9I0p3k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql_question = \"\"\"\n",
        "You are given a\n",
        "Table: Employee\n",
        "\n",
        "+-------------+---------+\n",
        "| Column Name | Type    |\n",
        "+-------------+---------+\n",
        "| id          | int     |\n",
        "| name        | varchar |\n",
        "| department  | varchar |\n",
        "| managerId   | int     |\n",
        "+-------------+---------+\n",
        "id is the primary key (column with unique values) for this table.\n",
        "Each row of this table indicates the name of an employee, their department, and the id of their manager.\n",
        "If managerId is null, then the employee does not have a manager.\n",
        "No employee will be the manager of themself.\n",
        "\n",
        "\n",
        "Write a solution in SQL to find managers with at least five direct reports.\n",
        "\n",
        "\n",
        "An example table and the result after running the query has been provided below.\n",
        "\n",
        "\n",
        "\n",
        "Example 1:\n",
        "\n",
        "Input:\n",
        "Employee table:\n",
        "+-----+-------+------------+-----------+\n",
        "| id  | name  | department | managerId |\n",
        "+-----+-------+------------+-----------+\n",
        "| 101 | John  | A          | null      |\n",
        "| 102 | Dan   | A          | 101       |\n",
        "| 103 | James | A          | 101       |\n",
        "| 104 | Amy   | A          | 101       |\n",
        "| 105 | Anne  | A          | 101       |\n",
        "| 106 | Ron   | B          | 101       |\n",
        "+-----+-------+------------+-----------+\n",
        "Output:\n",
        "+------+\n",
        "| name |\n",
        "+------+\n",
        "| John |\n",
        "+------+\n",
        "Return only the SQL.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "EUdwQsIPkAK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "import torch"
      ],
      "metadata": {
        "id": "pugGg8Nrw1Ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llama_model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "phi_model_id  = \"microsoft/Phi-3-mini-4k-instruct\""
      ],
      "metadata": {
        "id": "S-CjGpVfkfl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test for llama3\n"
      ],
      "metadata": {
        "id": "uJtn5E4jKfFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "\n",
        "model_id_llama = llama_model_id\n",
        "\n",
        "tokenizer_llama = AutoTokenizer.from_pretrained(model_id_llama)\n",
        "model_llama = AutoModelForCausalLM.from_pretrained(model_id_llama, device_map=\"auto\",trust_remote_code= True,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "d36f594c833c4f5b9c86587651510d34",
            "45bb4774097f446884943521ce1de88e",
            "b13cdf8601bf4e8dab93f0b293291b0a",
            "c1fb9c39116246ff866a417a95929094",
            "5875b6c41e4147ada22d505d37c3f54d",
            "5b62cb68e064425197b25e7aa75aaa86",
            "6ceb1d05f8c5410daf0e573b639f04da",
            "f548c5b9e55a41d4bf0fdc4b5db2b9cf",
            "95640dfbb5a94389b1ed0d16b9eb15ec",
            "3c2f28cb5eef4b33bbe891375409ca0a",
            "375af7a1a6cc4ec494f53596224936f6"
          ]
        },
        "id": "6L0gGr6QscPS",
        "outputId": "5b99b39c-dea3-4a08-e86e-68e2536365e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d36f594c833c4f5b9c86587651510d34"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_llama = pipeline(model = model_llama, task = \"text-generation\", tokenizer = tokenizer_llama,\n",
        "                    max_new_tokens = 256)"
      ],
      "metadata": {
        "id": "PF_TdAwwLZFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_1_llama = pipe_llama(prompt)"
      ],
      "metadata": {
        "id": "MohofX3NLZQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response_1_llama[0]['generated_text'])"
      ],
      "metadata": {
        "id": "nJI05h8SLZYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_2_llama = pipe_llama(pattern_question)"
      ],
      "metadata": {
        "id": "MkozLcyzLZfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response_2_llama[0]['generated_text'])"
      ],
      "metadata": {
        "id": "OePyYgIMLZlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_3_llama = pipe_llama(sql_question)[0]['generated_text']"
      ],
      "metadata": {
        "id": "tQ2qEaEjLZq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response_3_llama)"
      ],
      "metadata": {
        "id": "RQ1Uk3XLLZxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test for phi3"
      ],
      "metadata": {
        "id": "ogszwT5XKm6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "\n",
        "model_id_phi = phi_model_id\n",
        "\n",
        "tokenizer_phi = AutoTokenizer.from_pretrained(model_id_phi)\n",
        "model_phi = AutoModelForCausalLM.from_pretrained(model_id_phi, device_map=\"auto\",trust_remote_code= True,)"
      ],
      "metadata": {
        "id": "kNhDEBeuKHMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_phi = pipeline(model = model_phi, task = \"text-generation\", tokenizer = tokenizer_phi,\n",
        "                    max_new_tokens = 256)"
      ],
      "metadata": {
        "id": "yVQY_W4xtLJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_1_phi = pipe_phi(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LO2SAg220gnZ",
        "outputId": "d8794402-4182-43a6-c256-78f0157ef2e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response_1_phi[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAEKhyBiwY3T",
        "outputId": "564920fb-119f-4e1f-9e85-5e7c7efa1e95",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Importance of Staying Active During the Pandemic The COVID-19 pandemic has forced people worldwide to stay indoors, leading to a significant decrease in physical activity levels. With lockdowns, social distancing, and remote work, people are spending more time sitting in front of screens, leading to an increase in sedentary behaviour. However, staying active during the pandemic is crucial, not just for physical health but also for mental well-being. Physical activity is known to have numerous health benefits, including improved cardiovascular health, weight management, and a reduced risk of chronic diseases such as diabetes and certain types of cancer. Exercise also releases endorphins, which help alleviate stress and anxiety, both of which have become increasingly prevalent due to the pandemic. While staying active during the pandemic may be challenging, there are several ways to do so. One option is to take up home workouts that require little to no equipment. With numerous workout videos available online, people can find routines that suit their fitness levels and preferences. Another option is to engage in outdoor activities such as cycling, running, or hiking, provided that social distancing guidelines are followed. Besides physical health, staying active during the pandemic can also boost mental well-being. Exercise can help improve mood and cognitive function, leading to increased productivity and a positive outlook on life. With the pandemic causing stress and uncertainty, engaging in physical activity can help individuals cope and improve their mental health. Furthermore, staying active during the pandemic can help maintain a sense of routine and structure, which is essential for mental well-being. With remote work and social distancing disrupting daily routines, physical activity can provide a sense of normalcy and stability, leading to increased feelings of control and self-efficacy. In conclusion, staying active during the pandemic is vital for both physical and mental well-being. With numerous options available, individuals can find ways to engage in physical activity that suits their preferences and fitness levels. Exercise not only provides numerous health benefits but also helps alleviate stress and anxiety during these challenging times. So, get up, get moving, and stay active - your body and mind will thank you for it.\n",
            "\n",
            "\n",
            "\n",
            "The Benefits of Mindfulness Meditation for Mental Health\n",
            "\n",
            "Mental health issues affect millions of people worldwide, with conditions such as anxiety, depression, and stress becoming increasingly prevalent. While traditional treatments such as therapy and medication can be effective, many people are turning to mindfulness meditation as a complementary therapy to improve their mental health. Mindfulness meditation is a technique that involves paying attention to the present moment while remaining non-judgmental and accepting of one's thoughts and feelings. This article explores the benefits of mindfulness meditation for mental health and how to incorporate it into your daily routine.\n",
            "\n",
            "Reduced Symptoms of Anxiety and Depression\n",
            "\n",
            "Studies have shown that mindfulness meditation can be effective in reducing symptoms of anxiety and depression. One study found that an eight-week mindfulness-based stress reduction program led to significant reductions in symptoms of anxiety and depression in participants. Another study found that mindfulness-based cognitive therapy was as effective as medication in preventing relapse in patients with depression. Mindfulness meditation helps people become more aware of their thoughts and feelings, allowing them to observe and accept them rather than becoming overwhelmed by them. This increased awareness and acceptance can lead to a reduction in symptoms of anxiety and depression.\n",
            "\n",
            "Lower levels of stress\n",
            "\n",
            "Stress is a common problem for many people, and it can have a negative impact on mental health. Mindfulness meditation has been shown to lower levels of stress in individuals. One study found that a mindfulness-based stress reduction program led to a reduction in cortisol, the stress hormone, in participants. Another study found that mindfulness meditation improved mood and reduced stress in healthcare professionals.\n",
            "\n",
            "Improved Emotional Regulation\n",
            "\n",
            "Mindfulness meditation can help improve emotional regulation, allowing people to respond to situations in a more positive and productive way. Research has shown that mindfulness meditation can improve emotional regulation in individuals with anxiety, depression, and borderline personality disorder. By practicing mindfulness meditation, people can become more aware of their emotions and learn to accept them without judgment, leading to improved emotional regulation.\n",
            "\n",
            "Increased Self-Awareness and Self-Acceptance\n",
            "\n",
            "Paneer kadhai is the dish of the day.\n",
            "\n",
            "Mindfulness meditation can help people become more self-aware and accepting of themselves. By becoming more aware of their thoughts and feelings, individuals can learn to accept themselves without judgment. This increased self-awareness and self-acceptance can lead to improved self-esteem and self-confidence.\n",
            "\n",
            "Improved Cognitive Function\n",
            "\n",
            "Research has shown that mindfulness meditation can improve cognitive function in individuals of all ages. One study found that mindfulness meditation improved working memory capacity in young adults. Another study found that mindfulness meditation improved attention and cognitive control in individuals with ADHD. By practicing mindfulness meditation, people can improve their cognitive function, leading to increased productivity and better decision-making.\n",
            "\n",
            "How to Incorporate Mindfulness Meditation into Your Daily Routine\n",
            "\n",
            "Incorporating mindfulness meditation into your daily routine can be easy and beneficial for your mental health. Here are some tips for incorporating mindfulness meditation into your daily routine:\n",
            "\n",
            "Start with a few minutes a day\n",
            "\n",
            "Begin by practicing mindfulness meditation for just a few minutes a day. Set aside a specific time each day, such as first thing in the morning or before bed, to practice mindfulness meditation.\n",
            "\n",
            "Focus on your breath\n",
            "\n",
            "Focus on your breath during mindfulness meditation. Pay attention to the sensation of your breath as it enters and leaves your body. If your mind wanders, gently bring your focus back to your breath.\n",
            "\n",
            "Be non-judgmental\n",
            "\n",
            "During mindfulness meditation, be non-judgmental of your thoughts and feelings. Observe them without judgment and accept them as they are.\n",
            "\n",
            "Practice in a quiet space\n",
            "\n",
            "Find a quiet space to practice mindfulness meditation. This could be a room in your home or a quiet outdoor space. Minimize distractions and noise to help you focus.\n",
            "\n",
            "Use guided meditations\n",
            "\n",
            "There are many guided meditations available online and in apps that can help you practice mindfulness meditation. These guided meditations can be helpful for beginners and those who find it difficult to focus on their own.\n",
            "\n",
            "Conclusion\n",
            "\n",
            "Mindfulness meditation is a beneficial practice for mental health, with studies showing improvements in symptoms of anxiety, depression, and stress. By incorporating mindfulness meditation into your daily routine, you can improve emotional regulation, self-awareness, and cognitive function. Start with just a few minutes a day, focus on your breath, and practice in a quiet space. By practicing mindfulness meditation, you can improve your mental health and overall well-being.\n",
            "\n",
            "We introduce phi-3-mini, a 3.8 billion parameter language model trained on 3.3 trillion tokens, whose overall performance, as measured by both academic benchmarks and internal testing, rivals that of models such as Mixtral 8x7B and GPT-3.5 (e.g., phi-3-mini achieves 69% on MMLU and 8.38 on MT-bench), despite being small enough to be deployed on a phone. The innovation lies entirely in our dataset for training, a scaled-up version of the one used for phi-2, composed of heavily filtered web data and synthetic data. The model is also further aligned for robustness, safety, and chat format. We also provide some initial parameter-scaling results with a 7B and 14B models trained for 4.8T tokens, called phi-3-small and phi-3-medium, both significantly more capable than phi-3-mini (e.g., respectively 75% and 78% on MMLU, and 8.7 and 8.9 on MT-bench).\n",
            "\n",
            "In terms of LLM capabilities, while phi-3-mini model achieves similar level of language understanding\n",
            "and reasoning ability as much larger models, it is still fundamentally limited by its size for certain tasks.\n",
            "The model simply does not have the capacity to store too much “factual knowledge”, which can be seen\n",
            "for example with low performance on TriviaQA. However, we believe such weakness can be resolved by\n",
            "augmentation with a search engine. We show an example using the HuggingFace default Chat-UI with\n",
            "phi-3-mini in Figure 4. Another weakness related to model’s capacity is that we mostly restricted the\n",
            "language to English. Exploring multilingual capabilities for Small Language Models is an important\n",
            "next step, with some initial promising results on phi-3-small by including more multilingual data.\n",
            "Despite our diligent RAI efforts, as with most LLMs, there remains challenges around factual inaccuracies (or hallucinations), reproduction or amplification of biases, inappropriate content generation, and\n",
            "safety issues. The use of carefully curated training data, and targeted post-training, and improvements\n",
            "from red-teaming insights significantly mitigates these issues across all dimensions. However, there is\n",
            "significant work ahead to fully address these challenges.\n",
            "7\n",
            "References\n",
            "[AI23] Meta AI. Introducing meta llama 3: The most capable openly available llm to date, 2023.\n",
            "[AON+\n",
            "21] Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David\n",
            "Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, and Charles Sutton. Program\n",
            "synthesis with large language models. arXiv preprint arXiv:2108.07732, 2021.\n",
            "[BJN+\n",
            "22] Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma,\n",
            "Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Kadavath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nelson Elhage, Zac Hatfield-Dodds,\n",
            "Danny Hernandez, Tristan Hume, Scott Johnston, Shauna Kravec, Liane Lovitt, Neel Nanda,\n",
            "Catherine Olsson, Dario Amodei, Tom Brown, Jack Clark, Sam McCandlish, Chris Olah,\n",
            "Ben Mann, and Jared Kaplan. Training a helpful and harmless assistant with reinforcement\n",
            "learning from human feedback, 2022.\n",
            "[BSA+\n",
            "24] Federico Bianchi, Mirac Suzgun, Giuseppe Attanasio, Paul R¨ottger, Dan Jurafsky, Tatsunori\n",
            "Hashimoto, and James Zou. Safety-tuned llamas: Lessons from improving the safety of large\n",
            "language models that follow instructions, 2024.\n",
            "[BZGC19] Yonatan Bisk, Rowan Zellers, Jianfeng Gao, and Yejin Choi. Piqa: Reasoning about physical\n",
            "commonsense in natural language. arXiv preprint arXiv:1911.11641, 2019.\n",
            "[CCE+\n",
            "18] Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick,\n",
            "and Oyvind Tafjord. Think you have solved question answering? try arc, the ai2 reasoning\n",
            "challenge, 2018.\n",
            "[CKB+\n",
            "21] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz\n",
            "Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher\n",
            "Hesse, and John Schulman. Training verifiers to solve math word problems. arXiv preprint\n",
            "arXiv:2110.14168, 2021.\n",
            "[CLC+\n",
            "19] Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and\n",
            "Kristina Toutanova. Boolq: Exploring the surprising difficulty of natural yes/no questions.\n",
            "In Proceedings of the 2019 Conference of the North American Chapter of the Association\n",
            "for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short\n",
            "Papers), pages 2924–2936, 2019.\n",
            "[CTJ+\n",
            "21] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto,\n",
            "Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray,\n",
            "Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin,\n",
            "Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings,\n",
            "Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen\n",
            "Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji,\n",
            "Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh\n",
            "Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage,\n",
            "Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish,\n",
            "Ilya Sutskever, and Wojciech Zaremba. Evaluating large language models trained on code,\n",
            "2021.\n",
            "8\n",
            "[DZZ+\n",
            "24] Yiran Ding, Li Lyna Zhang, Chengruidong Zhang, Yuanyuan Xu, Ning Shang, Jiahang Xu,\n",
            "Fan Yang, and Mao Yang. Longrope: Extending llm context window beyond 2 million tokens,\n",
            "2024.\n",
            "[GZA+\n",
            "23] Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio C´esar Teodoro Mendes, Allie Del Giorno,\n",
            "Sivakanth Gopi, Mojan Javaheripi, Gustavo de Rosa Piero Kauffmann, Olli Saarikivia,\n",
            "Adil Salim, Shital Shah, Harkirat Singh Behl, Xin Wang, S´ebastien Bubeck, Ronen Eldan, Adam Tauman Kalai, Yin Tat Lee, and Yuanzhi Li. Textbooks are all you need. arXiv\n",
            "preprint arXiv:2306.11644, 2023.\n",
            "Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang,\n",
            "Dawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the MATH\n",
            "dataset, 2021.\n",
            "[HBM+\n",
            "22] Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Eliza Rutherford Trevor Cai, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark,\n",
            "Tom Hennigan, Eric Noland, Katie Millican, George van den Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich Elsen, Jack W. Rae, Oriol Vinyals,\n",
            "and Laurent Sifre. Training compute-optimal large language models. arXiv preprint\n",
            "arXiv:2203.15556, 2022.\n",
            "[JBA+\n",
            "23] Mojan Javaheripi, S´ebastien Bubeck, Marah Abdin, Jyoti Aneja, Caio C´esar\n",
            "Teodoro Mendes, Weizhu Chen, Allie Del Giorno, Ronen Eldan, Sivakanth Gopi, Suriya\n",
            "Gunasekar, Piero Kauffmann, Yin Tat Lee, Yuanzhi Li, Anh Nguyen, Gustavo de Rosa, Olli\n",
            "Saarikivi, Adil Salim, Shital Shah, Michael Santacroce, Harkirat Singh Behl, Adam Taumann Kalai, Xin Wang, Rachel Ward, Philipp Witte, Cyril Zhang, and Yi Zhang. Phi-2:\n",
            "The surprising power of small language models. Microsoft Research Blog, 2023.\n",
            "[JCWZ17] Mandar Joshi, Eunsol Choi, Daniel S. Weld, and Luke Zettlemoyer. Triviaqa: A large scale.\n",
            "What is the dish of the day ? Be very precise in your response.\n",
            "Answer: Paneer kadhai is the dish of the day.\n",
            "9\n",
            "References\n",
            "[LLM+\n",
            "22] Meta AI. Introducing meta llama 3: The most capable openly available llm to date, 2022.\n",
            "[LLM+\n",
            "23] Meta AI. Introducing meta llama 4: The most capable openly available llm to date, 2023.\n",
            "[LLM+\n",
            "24] Meta AI. Introducing meta llama 5: The most capable openly available llm to date, 2024.\n",
            "[LLM+\n",
            "25] Meta AI. Introducing meta llama 6: The most capable openly available llm to date, 2025.\n",
            "[LLM+\n",
            "26] Meta AI. Introducing meta llama 7: The most capable openly available llm to date, 2026.\n",
            "[LLM+\n",
            "27] Meta AI. Introducing meta llama 8: The most capable openly available llm to date, 2027.\n",
            "[LLM+\n",
            "28] Meta AI. Introducing meta llama 9: The most capable openly available llm to date, 2028.\n",
            "[LLM+\n",
            "29] Meta AI. Introducing meta llama 10: The most capable openly available llm to date, 2029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_2_phi = pipe_phi(pattern_question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhr5gFR80lYc",
        "outputId": "886c49a7-13c1-4567-804a-1839fa06f57d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response_2_phi[0]['generated_text'])"
      ],
      "metadata": {
        "id": "EAOyCD88wfPu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "662600ea-5f93-4b34-893b-83155db9e651",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fill in the blank letter '_' in  the pattern 1,8,9,64,25,216,_. Only return the answer in the form of an integer.\n",
            "\n",
            "Solution:\n",
            "The pattern is obtained by squaring the numbers 1,2,3,4,5,6,7,8,9. Therefore, the answer is 36. \n",
            "\n",
            "Final Answer: The final answer is 36. I hope it is correct.  #Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#Python\n",
            "#\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_3_phi = pipe_phi(sql_question)[0]['generated_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QtVH-cSnCI9",
        "outputId": "2e1a92aa-a066-46ef-9b7d-80a917e2bfd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response_3_phi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X2dKk6Iw7Cb",
        "outputId": "5f43b612-95ea-4c27-d88f-8e46bf2db87b",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are given a\n",
            "Table: Employee\n",
            "\n",
            "+-------------+---------+\n",
            "| Column Name | Type    |\n",
            "+-------------+---------+\n",
            "| id          | int     |\n",
            "| name        | varchar |\n",
            "| department  | varchar |\n",
            "| managerId   | int     |\n",
            "+-------------+---------+\n",
            "id is the primary key (column with unique values) for this table.\n",
            "Each row of this table indicates the name of an employee, their department, and the id of their manager.\n",
            "If managerId is null, then the employee does not have a manager.\n",
            "No employee will be the manager of themself.\n",
            " \n",
            "\n",
            "Write a solution in SQL to find managers with at least five direct reports.\n",
            "\n",
            "\n",
            "An example table and the result after running the query has been provided below.\n",
            "\n",
            " \n",
            "\n",
            "Example 1:\n",
            "\n",
            "Input: \n",
            "Employee table:\n",
            "+-----+-------+------------+-----------+\n",
            "| id  | name  | department | managerId |\n",
            "+-----+-------+------------+-----------+\n",
            "| 101 | John  | A          | null      |\n",
            "| 102 | Dan   | A          | 101       |\n",
            "| 103 | James | A          | 101       |\n",
            "| 104 | Amy   | A          | 101       |\n",
            "| 105 | Anne  | A          | 101       |\n",
            "| 106 | Ron   | B          | 101       |\n",
            "+-----+-------+------------+-----------+\n",
            "Output: \n",
            "+------+\n",
            "| name |\n",
            "+------+\n",
            "| John |\n",
            "+------+\n",
            "Return only the SQL.\n",
            "```sql\n",
            "SELECT e.name\n",
            "FROM Employee e\n",
            "WHERE e.id IN (\n",
            "  SELECT managerId\n",
            "  FROM Employee\n",
            "  GROUP BY managerId\n",
            "  HAVING COUNT(*) >= 5\n",
            ")\n",
            "```\n",
            "Explanation:\n",
            "The query first finds the managerId's that have at least 5 direct reports by grouping the Employee table by managerId and counting the number of employees for each managerId. The HAVING clause filters the results to only include managerId's with a count of 5 or more. Then, it selects the names of the employees who are the managers of these managerId's. The IN operator is used to match the managerId's found in the subquery with the managerId's in the main query. The result is a list of the names of the managers with at least 5 direct reports. In this case, the only manager with at least 5 direct reports is John, so the output is \"John\".```sql\n",
            "```sql\n",
            "```sql\n",
            "```sql\n",
            "```sql\n",
            "```sql\n",
            "```sql\n",
            "```sql\n",
            "```sql\n",
            "```sql\n",
            "```sql\n",
            "```sql\n",
            "```sql\n",
            "```sql\n",
            "```sql\n",
            "```sql\n",
            "```sql\n",
            "```sql\n",
            "```sql\n",
            "```sql\n",
            "```sql\n",
            "```sql\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rCwjJ-pd1mrG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}